{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8936f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "\n",
    "SEED = 12345\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "VALIDATION_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c84d858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "122e2e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((610, 4980), (610, 4980), (4980, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_train_np = np.load('ratings_train.npy')\n",
    "namesngenre_np = np.load('namesngenre.npy')\n",
    "ratings_test_np = np.load('ratings_test.npy')\n",
    "ratings_train_np.shape, ratings_test_np.shape, namesngenre_np.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35a7cfb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1900, 1910, 1920, 1930, 1940, 1950, 1960, 1970, 1980, 1990, 2000, 2010}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "year_pattern = re.compile(r\"\\((\\d{4})\\)\")\n",
    "all_decades = set(int(year_pattern.search(name.item()).group(1)) // 10 * 10 for name, _ in namesngenre_np if year_pattern.search(name.item()))\n",
    "num_decades = len(all_decades)\n",
    "all_decades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37d31dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    1,    2,  ..., 4977, 4978, 4979],\n",
       "        [   9,    9,    9,  ...,   10,   11,   11]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_decades = sorted(all_decades)\n",
    "decade_to_index = {decade: idx for idx, decade in enumerate(sorted_decades)}\n",
    "# Each edge connects a movie (row index in namesngenre_np) to its release decade\n",
    "decade_edges = []\n",
    "for movie_idx, (raw_name, _) in enumerate(namesngenre_np):\n",
    "    match = year_pattern.search(raw_name.item())\n",
    "    if match:\n",
    "        decade = int(match.group(1)) // 10 * 10\n",
    "        decade_edges.append((movie_idx, decade_to_index[decade]))\n",
    "decade_edges = torch.tensor(decade_edges, dtype=torch.long).t() if decade_edges else torch.empty((2, 0), dtype=torch.long)\n",
    "decade_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c183294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action',\n",
       " 'Adventure',\n",
       " 'Animation',\n",
       " 'Children',\n",
       " 'Comedy',\n",
       " 'Crime',\n",
       " 'Documentary',\n",
       " 'Drama',\n",
       " 'Fantasy',\n",
       " 'Film-Noir',\n",
       " 'Horror',\n",
       " 'IMAX',\n",
       " 'Musical',\n",
       " 'Mystery',\n",
       " 'Romance',\n",
       " 'Sci-Fi',\n",
       " 'Thriller',\n",
       " 'War',\n",
       " 'Western']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_genres = set(g for _, genres in namesngenre_np for g in genres.split('|'))\n",
    "all_genres.discard('(no genres listed)')\n",
    "all_genres = sorted(list(all_genres))\n",
    "num_genres = len(all_genres)\n",
    "all_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "929ade35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,  ..., 4978, 4978, 4979],\n",
       "        [   1,    2,    3,  ...,    1,    8,    4]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_to_index = {genre: idx for idx, genre in enumerate(all_genres)}\n",
    "# Each edge connects a movie to one of its genres without applying offsets\n",
    "genre_edges = []\n",
    "for movie_idx, (_, genres_str) in enumerate(namesngenre_np):\n",
    "    for genre in genres_str.split('|'):\n",
    "        genre = genre.strip()\n",
    "        if genre in genre_to_index:\n",
    "            genre_edges.append((movie_idx, genre_to_index[genre]))\n",
    "genre_edges = torch.tensor(genre_edges, dtype=torch.long).t() if genre_edges else torch.empty((2, 0), dtype=torch.long)\n",
    "genre_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae929717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# genre_map = {genre: i for i, genre in enumerate(all_genres)}\n",
    "# movie_features = torch.zeros(namesngenre_np.shape[0], len(all_genres))\n",
    "# for i, (_, genres_str) in enumerate(namesngenre_np):\n",
    "#     for genre in genres_str.split('|'):\n",
    "#         if genre in genre_map:\n",
    "#             movie_features[i, genre_map[genre]] = 1\n",
    "\n",
    "# movie_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da3a6540",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users, num_movies = ratings_train_np.shape\n",
    "# user_features = torch.rand(num_users, len(all_genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd5587ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 28438), (28438,), (2, 3160), (3160,), (2, 31598), (31598,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids, movie_ids = np.where(~np.isnan(ratings_train_np))\n",
    "ratings = ratings_train_np[~np.isnan(ratings_train_np)]\n",
    "\n",
    "test_user_ids, test_movie_ids = np.where(~np.isnan(ratings_test_np))\n",
    "test_ratings = ratings_test_np[~np.isnan(ratings_test_np)]\n",
    "\n",
    "edges = np.column_stack((user_ids, movie_ids))\n",
    "train_edges, val_edges, train_ratings, val_ratings = train_test_split(\n",
    "    edges, ratings, test_size=VALIDATION_SPLIT, random_state=SEED, shuffle=True\n",
    ")\n",
    "train_edges, val_edges = train_edges.T, val_edges.T\n",
    "\n",
    "test_edges = np.column_stack((test_user_ids, test_movie_ids)).T\n",
    "ratings = ratings.astype(np.float32)\n",
    "test_ratings = test_ratings.astype(np.float32)\n",
    "train_edges.shape, train_ratings.shape, val_edges.shape, val_ratings.shape, test_edges.shape, test_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfe387b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 28438]), torch.Size([2, 3160]), torch.Size([2, 31598]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def offset_edges(edge_tensor, src_offset=0, dst_offset=0):\n",
    "    if edge_tensor.numel() == 0:\n",
    "        return torch.empty((2, 0), dtype=torch.long)\n",
    "    adjusted = edge_tensor.clone()\n",
    "    adjusted[0, :] += src_offset\n",
    "    adjusted[1, :] += dst_offset\n",
    "    return adjusted\n",
    "\n",
    "movie_offset = num_users\n",
    "genre_offset = num_users + num_movies\n",
    "decade_offset = num_users + num_movies + num_genres\n",
    "\n",
    "train_edge_index = torch.tensor(train_edges, dtype=torch.long)\n",
    "val_edge_index = torch.tensor(val_edges, dtype=torch.long)\n",
    "test_edge_index = torch.tensor(test_edges, dtype=torch.long)\n",
    "\n",
    "train_edge_index = offset_edges(train_edge_index, 0, movie_offset)\n",
    "val_edge_index = offset_edges(val_edge_index, 0, movie_offset)\n",
    "test_edge_index = offset_edges(test_edge_index, 0, movie_offset)\n",
    "\n",
    "train_actual_ratings = torch.tensor(train_ratings, dtype=torch.float32)\n",
    "val_actual_ratings = torch.tensor(val_ratings, dtype=torch.float32)\n",
    "test_actual_ratings = torch.tensor(test_ratings, dtype=torch.float32)\n",
    "\n",
    "genre_edge_index = offset_edges(genre_edges, movie_offset, genre_offset)\n",
    "decade_edge_index = offset_edges(decade_edges, movie_offset, decade_offset)\n",
    "\n",
    "train_edge_index.shape, val_edge_index.shape, test_edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6ac040df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels_list, concat_outputs=False):\n",
    "        super(GCN, self).__init__()\n",
    "        self.concat_outputs = concat_outputs\n",
    "        self.layers_list = torch.nn.ModuleList()\n",
    "        prev_channels = in_channels\n",
    "        for hidden_channels in hidden_channels_list:\n",
    "            self.layers_list.append(\n",
    "                GCNConv(prev_channels, hidden_channels),\n",
    "            )\n",
    "            prev_channels = hidden_channels\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        if self.concat_outputs:\n",
    "            hidden_outputs = []\n",
    "            for idx, layer in enumerate(self.layers_list):\n",
    "                is_last = (idx == len(self.layers_list) - 1)\n",
    "                x = layer(x, edge_index)\n",
    "                if not is_last:\n",
    "                    x = F.relu(x)\n",
    "                hidden_outputs.append(x)\n",
    "            x = torch.cat(hidden_outputs, dim=1)\n",
    "        else:\n",
    "            for idx, layer in enumerate(self.layers_list):\n",
    "                is_last = (idx == len(self.layers_list) - 1)\n",
    "                x = layer(x, edge_index)\n",
    "                if not is_last:\n",
    "                    x = F.relu(x)\n",
    "        return x\n",
    "    \n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels_list, concat_outputs=False, heads=8, dropout=0.1):\n",
    "        super(GAT, self).__init__()\n",
    "        self.concat_outputs = concat_outputs\n",
    "        self.layers_list = torch.nn.ModuleList()\n",
    "        prev_channels = in_channels\n",
    "        prev_heads = 1\n",
    "        for idx, hidden_channels in enumerate(hidden_channels_list):\n",
    "            is_last = (idx == len(hidden_channels_list) - 1)\n",
    "            self.layers_list.append(\n",
    "                GATConv(prev_channels * prev_heads, hidden_channels, heads=heads, dropout=dropout, concat=False if is_last else True),\n",
    "            )\n",
    "            prev_channels = hidden_channels\n",
    "            prev_heads = heads\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        if self.concat_outputs:\n",
    "            hidden_outputs = []\n",
    "            for idx, layer in enumerate(self.layers_list):\n",
    "                is_last = (idx == len(self.layers_list) - 1)\n",
    "                x = layer(x, edge_index)\n",
    "                if not is_last:\n",
    "                    x = F.elu(x)\n",
    "                hidden_outputs.append(x)\n",
    "            x = torch.cat(hidden_outputs, dim=1)\n",
    "        else:\n",
    "            for idx, layer in enumerate(self.layers_list):\n",
    "                is_last = (idx == len(self.layers_list) - 1)\n",
    "                x = layer(x, edge_index)\n",
    "                if not is_last:\n",
    "                    x = F.elu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd789f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    # General Training Parameters\n",
    "    'num_epochs': 10000,\n",
    "    'batch_size': 2**12,\n",
    "    'learning_rate': 0.001,\n",
    "    'patience': 200,\n",
    "    'scale_function': 'sigmoid',  # Options: 'sigmoid', 'clamp' sigmoind works better\n",
    "    # Model Parameters\n",
    "    # 'MODEL_TYPE': 'GCN',  # Options: 'GCN', 'GAT'\n",
    "    \n",
    "    # 'concat_outputs': False,\n",
    "    \n",
    "    # 'num_features': 32,\n",
    "    \n",
    "    # 'hidden_dims': (32,) * 2,\n",
    "    # Best Val Loss: 0.9446, during training was 0.9446\n",
    "    # Test Loss: 0.9472\n",
    "\n",
    "    # 'hidden_dims': (32,) * 3,\n",
    "    # Best Val Loss: 0.9264, during training was 0.9264\n",
    "    # Test Loss: 0.9252\n",
    "\n",
    "    # 'hidden_dims': (32,) * 4,\n",
    "    # Best Val Loss: 0.9220, during training was 0.9220\n",
    "    # Test Loss: 0.9198\n",
    "\n",
    "    # 'hidden_dims': (32,) * 5,\n",
    "    # Best Val Loss: 0.9241, during training was 0.9241\n",
    "    # Test Loss: 0.9275\n",
    "\n",
    "    # 'hidden_dims': (32,) * 6,\n",
    "    # Best Val Loss: 0.9117, during training was 0.9117\n",
    "    # Test Loss: 0.9166\n",
    "    \n",
    "    # 'hidden_dims': (32,) * 7,\n",
    "    # Best Val Loss: 0.9141, during training was 0.9141\n",
    "    # Test Loss: 0.9163\n",
    "\n",
    "    # 'hidden_dims': (32,) * 8,\n",
    "    # Best Val Loss: 0.9098, during training was 0.9098\n",
    "    # Test Loss: 0.9146\n",
    "    \n",
    "    # 'hidden_dims': (32,) * 9,\n",
    "    # Best Val Loss: 0.9112, during training was 0.9112\n",
    "    # Test Loss: 0.9120\n",
    "    \n",
    "    # 'hidden_dims': (32,) * 10,\n",
    "    # Best Val Loss: 0.9050, during training was 0.9050\n",
    "    # Test Loss: 0.9131\n",
    "    \n",
    "    # 'hidden_dims': (32,) * 11,\n",
    "    # Best Val Loss: 0.9281, during training was 0.9281\n",
    "    # Test Loss: 0.9350\n",
    "    \n",
    "    # 'hidden_dims': (32,) * 12,\n",
    "    # Best Val Loss: 0.9277, during training was 0.9277\n",
    "    # Test Loss: 0.9338\n",
    "    \n",
    "    # 'hidden_dims': (32,) * 20,\n",
    "    # Best Val Loss: 0.9258, during training was 0.9258\n",
    "    # Test Loss: 0.9333\n",
    "    \n",
    "    # 'concat_outputs': True,\n",
    "    \n",
    "    # 'hidden_dims': (32,) * 10,\n",
    "    # Best Val Loss: 0.9320, during training was 0.9320\n",
    "    # Test Loss: 0.9385\n",
    "    \n",
    "    # 'hidden_dims': (32,) * 20,\n",
    "    # Best Val Loss: 0.9306, during training was 0.9306\n",
    "    # Test Loss: 0.9346\n",
    "\n",
    "    # Test Num Features:\n",
    "    # 'hidden_dims': (32,) * 6,\n",
    "    # 'num_features': 32,\n",
    "    # Best Val Loss: 0.9258, during training was 0.9258\n",
    "    # Test Loss: 0.9327\n",
    "    # 'num_features': 64,\n",
    "    # Best Val Loss: 0.9185, during training was 0.9185\n",
    "    # Test Loss: 0.9164\n",
    "    # 'num_features': 128,\n",
    "    # Best Val Loss: 0.9260, during training was 0.9260\n",
    "    # Test Loss: 0.9337\n",
    "    \n",
    "    # 'concat_outputs' : False,\n",
    "    # 'num_features': 64,\n",
    "    # optimal depth seems to be 10\n",
    "    # concatenating outputs seems to worsen performance\n",
    "    \n",
    "    # testing decreasing hidden dims with depth 10\n",
    "    # 'hidden_dims': (128, 112, 96, 80, 64, 48, 32, 24, 16, 8),\n",
    "    # Best Val Loss: 0.9150, during training was 0.9150\n",
    "    # Test Loss: 0.9206\n",
    "    \n",
    "    # testing a wider network with depth 10\n",
    "    # 'hidden_dims': (64,) * 10,\n",
    "    # Best Val Loss: 0.9142, during training was 0.9142\n",
    "    # Test Loss: 0.9152\n",
    "\n",
    "    # 'hidden_dims': (128,) * 10,\n",
    "    # Best Val Loss: 0.9104, during training was 0.9104\n",
    "    # Test Loss: 0.9156\n",
    "    \n",
    "    # 'hidden_dims': (256,) * 10,\n",
    "    # Best Val Loss: 0.9073, during training was 0.9073\n",
    "    # Test Loss: 0.9115\n",
    "    \n",
    "    # 'hidden_dims': (512,) * 10,\n",
    "    # Not trainable\n",
    "    \n",
    "    'MODEL_TYPE': 'GAT',\n",
    "\n",
    "    # 'concat_outputs' : False,\n",
    "    \n",
    "    'num_features': 64,\n",
    "    # 'hidden_dims': (32,) * 10,\n",
    "    # Best Val Loss: 0.8985, during training was 0.8985\n",
    "    # Test Loss: 0.8973\n",
    "    \n",
    "    # 'hidden_dims': (16,) * 8,\n",
    "    # Best Val Loss: 0.8998, during training was 0.8998\n",
    "    # Test Loss: 0.9065\n",
    "    \n",
    "    # 'hidden_dims': (8,) * 8,\n",
    "    # Best Val Loss: 0.9299, during training was 0.9299\n",
    "    # Test Loss: 0.9303\n",
    "    \n",
    "    # 'concat_outputs': True,\n",
    "    # 'hidden_dims': (16,) * 8,\n",
    "    # Not trainable\n",
    "    #  'hidden_dims': (16,) * 6,\n",
    "    # Not trainable\n",
    "    # 'hidden_dims': (16,) * 4,\n",
    "    # Best Val Loss: 0.9500, during training was 0.9500\n",
    "    # Test Loss: 0.9521\n",
    "    \n",
    "    # concatenating outputs seems to worsen performance for GAT as well\n",
    "    \n",
    "    'concat_outputs': False,\n",
    "    'hidden_dims': (32,) * 12,\n",
    "    # Best Val Loss: 0.8983, during training was 0.8983\n",
    "    # Test Loss: 0.9028\n",
    "\n",
    "        \n",
    "    # FOR GAT:\n",
    "    'heads': 8,\n",
    "    'dropout': 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ef922f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_epochs': 10000, 'batch_size': 4096, 'learning_rate': 0.001, 'patience': 200, 'scale_function': 'sigmoid', 'MODEL_TYPE': 'GAT', 'num_features': 64, 'concat_outputs': False, 'hidden_dims': (32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32), 'heads': 8, 'dropout': 0.1}\n",
      "Starting training...\n",
      "Epoch: 000, Loss: 1.2541, Val Loss: 1.8023\n",
      "Epoch: 020, Loss: 1.0314, Val Loss: 1.0214\n",
      "Epoch: 040, Loss: 1.0173, Val Loss: 1.0167\n",
      "Epoch: 060, Loss: 1.0042, Val Loss: 0.9926\n",
      "Epoch: 080, Loss: 0.9951, Val Loss: 0.9853\n",
      "Epoch: 100, Loss: 0.9908, Val Loss: 0.9799\n",
      "Epoch: 120, Loss: 0.9875, Val Loss: 0.9718\n",
      "Epoch: 140, Loss: 0.9709, Val Loss: 0.9667\n",
      "Epoch: 160, Loss: 0.9647, Val Loss: 0.9699\n",
      "Epoch: 180, Loss: 0.9598, Val Loss: 0.9641\n",
      "Epoch: 200, Loss: 0.9679, Val Loss: 0.9494\n",
      "Epoch: 220, Loss: 0.9500, Val Loss: 0.9465\n",
      "Epoch: 240, Loss: 0.9477, Val Loss: 0.9434\n",
      "Epoch: 260, Loss: 0.9455, Val Loss: 0.9561\n",
      "Epoch: 280, Loss: 0.9501, Val Loss: 0.9419\n",
      "Epoch: 300, Loss: 0.9377, Val Loss: 0.9476\n",
      "Epoch: 320, Loss: 0.9345, Val Loss: 0.9400\n",
      "Epoch: 340, Loss: 0.9349, Val Loss: 0.9396\n",
      "Epoch: 360, Loss: 0.9342, Val Loss: 0.9287\n",
      "Epoch: 380, Loss: 0.9282, Val Loss: 0.9409\n",
      "Epoch: 400, Loss: 0.9340, Val Loss: 0.9282\n",
      "Epoch: 420, Loss: 0.9208, Val Loss: 0.9231\n",
      "Epoch: 440, Loss: 0.9172, Val Loss: 0.9260\n",
      "Epoch: 460, Loss: 0.9218, Val Loss: 0.9366\n",
      "Epoch: 480, Loss: 0.9137, Val Loss: 0.9188\n",
      "Epoch: 500, Loss: 0.9193, Val Loss: 0.9223\n",
      "Epoch: 520, Loss: 0.9137, Val Loss: 0.9274\n",
      "Epoch: 540, Loss: 0.9060, Val Loss: 0.9227\n",
      "Epoch: 560, Loss: 0.9113, Val Loss: 0.9175\n",
      "Epoch: 580, Loss: 0.9071, Val Loss: 0.9256\n",
      "Epoch: 600, Loss: 0.9117, Val Loss: 0.9158\n",
      "Epoch: 620, Loss: 0.9018, Val Loss: 0.9134\n",
      "Epoch: 640, Loss: 0.8990, Val Loss: 0.9122\n",
      "Epoch: 660, Loss: 0.8937, Val Loss: 0.9107\n",
      "Epoch: 680, Loss: 0.8888, Val Loss: 0.9099\n",
      "Epoch: 700, Loss: 0.8893, Val Loss: 0.9038\n",
      "Epoch: 720, Loss: 0.8867, Val Loss: 0.9064\n",
      "Epoch: 740, Loss: 0.8839, Val Loss: 0.9149\n",
      "Epoch: 760, Loss: 0.8919, Val Loss: 0.9163\n",
      "Epoch: 780, Loss: 0.8775, Val Loss: 0.9067\n",
      "Epoch: 800, Loss: 0.8784, Val Loss: 0.9122\n",
      "Epoch: 820, Loss: 0.8712, Val Loss: 0.9032\n",
      "Epoch: 840, Loss: 0.8789, Val Loss: 0.9103\n",
      "Epoch: 860, Loss: 0.8735, Val Loss: 0.9125\n",
      "Epoch: 880, Loss: 0.8689, Val Loss: 0.9039\n",
      "Epoch: 900, Loss: 0.8678, Val Loss: 0.9102\n",
      "Epoch: 920, Loss: 0.8584, Val Loss: 0.9076\n",
      "Epoch: 940, Loss: 0.8604, Val Loss: 0.9086\n",
      "Epoch: 960, Loss: 0.8532, Val Loss: 0.9104\n",
      "Epoch: 980, Loss: 0.8631, Val Loss: 0.9048\n",
      "Early stopping at epoch 990\n",
      "Training finished.\n",
      "Best Val Loss: 0.8983, during training was 0.8983\n",
      "Test Loss: 0.9028\n"
     ]
    }
   ],
   "source": [
    "print(CONFIG)\n",
    "\n",
    "x = torch.rand(num_users + num_movies + num_genres + num_decades, CONFIG['num_features'])\n",
    "\n",
    "train_edge_index = train_edge_index.to(device)\n",
    "val_edge_index = val_edge_index.to(device)\n",
    "test_edge_index = test_edge_index.to(device)\n",
    "val_actual_ratings = val_actual_ratings.to(device)\n",
    "test_actual_ratings = test_actual_ratings.to(device)\n",
    "\n",
    "genre_edge_index = genre_edge_index.to(device)\n",
    "decade_edge_index = decade_edge_index.to(device)\n",
    "graph_data = Data(x=x, edge_index=torch.concat([train_edge_index, genre_edge_index, decade_edge_index], axis=1), y=train_actual_ratings)\n",
    "graph_data = graph_data.to(device)\n",
    "\n",
    "scale_functions = {\n",
    "    'sigmoid': lambda x: torch.sigmoid(x) * 4.5 + .5,\n",
    "    'clamp': lambda x: x.clamp(.5, 5.0),\n",
    "}\n",
    "scale_function = scale_functions[CONFIG['scale_function']]\n",
    "\n",
    "if CONFIG['MODEL_TYPE'] == 'GCN':\n",
    "    model = GCN(in_channels=x.shape[1], hidden_channels_list=CONFIG['hidden_dims'], concat_outputs=CONFIG['concat_outputs'])\n",
    "elif CONFIG['MODEL_TYPE'] == 'GAT':\n",
    "    model = GAT(in_channels=x.shape[1], hidden_channels_list=CONFIG['hidden_dims'], concat_outputs=CONFIG['concat_outputs'], heads=CONFIG['heads'], dropout=CONFIG['dropout'])\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CONFIG['learning_rate'])\n",
    "criterion = torch.nn.MSELoss()\n",
    "best_val_loss = float('inf')\n",
    "best_model_state = None\n",
    "val_loss_not_improved_count = 0\n",
    "early_stopping_patience = CONFIG['patience']\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(CONFIG['num_epochs']):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    embeddings = model(graph_data.x, graph_data.edge_index)\n",
    "    user_embeds = embeddings[train_edge_index[0]]\n",
    "    movie_embeds = embeddings[train_edge_index[1]]\n",
    "    logits = (user_embeds * movie_embeds).sum(dim=1)\n",
    "    if CONFIG['scale_function'] == 'sigmoid':\n",
    "        predictions = scale_function(logits)\n",
    "    else:\n",
    "        predictions = logits\n",
    "    loss = criterion(predictions, graph_data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        eval_embeddings = model(graph_data.x, graph_data.edge_index)\n",
    "        val_user_embeds = eval_embeddings[val_edge_index[0]]\n",
    "        val_movie_embeds = eval_embeddings[val_edge_index[1]]\n",
    "        val_logits = (val_user_embeds * val_movie_embeds).sum(dim=1)\n",
    "        val_predictions = scale_function(val_logits)\n",
    "        val_loss = criterion(val_predictions, val_actual_ratings)\n",
    "        if epoch % 20 == 0:\n",
    "            print(f'Epoch: {epoch:03d}, Loss: {loss**.5:.4f}, Val Loss: {val_loss**.5:.4f}')\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            val_loss_not_improved_count = 0\n",
    "        else:\n",
    "            val_loss_not_improved_count += 1\n",
    "            if val_loss_not_improved_count >= early_stopping_patience:\n",
    "                print(f'Early stopping at epoch {epoch}')\n",
    "                break\n",
    "print(\"Training finished.\")\n",
    "\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    model = model.to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings = model(graph_data.x, graph_data.edge_index)\n",
    "    \n",
    "    val_user_embeds = embeddings[val_edge_index[0]]\n",
    "    val_movie_embeds = embeddings[val_edge_index[1]]\n",
    "    val_logits = (val_user_embeds * val_movie_embeds).sum(dim=1)\n",
    "    val_predictions = scale_function(val_logits)\n",
    "    val_loss = criterion(val_predictions, val_actual_ratings)\n",
    "    print(f'Best Val Loss: {val_loss**.5:.4f}, during training was {best_val_loss**.5:.4f}')\n",
    "    \n",
    "    test_user_embeds = embeddings[test_edge_index[0]]\n",
    "    test_movie_embeds = embeddings[test_edge_index[1]]\n",
    "    test_logits = (test_user_embeds * test_movie_embeds).sum(dim=1)\n",
    "    test_predictions = scale_function(test_logits)\n",
    "    test_loss = criterion(test_predictions, test_actual_ratings)\n",
    "    print(f'Test Loss: {test_loss**.5:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment1-2025-wecare (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
